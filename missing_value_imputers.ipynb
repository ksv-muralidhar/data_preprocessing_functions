{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61707dd4-5320-44c7-82a3-16d385c0b7c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68127fee-28cc-4354-9100-6923faae37f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NumAndNumImputer:\n",
    "    \n",
    "    '''\n",
    "    - Imputes a numeric feature using the values in another specified numeric feature.\n",
    "      Column pairs must be passed as input in the list of lists format like \n",
    "      [src_col, dest_col], where src_col and dest_col are numeric features.\n",
    "    \n",
    "    - src_col is the column to be used as key for imputation and dest_col is column to be imputed.\n",
    "    \n",
    "    - During model fit, src_col is binned and the median value of dest_col is computed and stored.\n",
    "    \n",
    "    - During transform, when a missing value is found in dest_col, it is imputed using the median value of\n",
    "      the corresponding bin in src_col computed while fitting the model.\n",
    "      \n",
    "      Inputs:\n",
    "      column_pairs: list[list[str]]\n",
    "          Column pairs to be used for imputation\n",
    "          \n",
    "      n_bins: int\n",
    "          Number of bins into whuch the src_col must be grouped using KBinsDiscretizer.\n",
    "          \n",
    "      binning_strategy: str: [\"uniform\", \"quantile\"]\n",
    "          Binning strategy to be used for binning the src_col using KBinsDiscretizer.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, column_pairs, n_bins=5, binning_strategy='quantile'):\n",
    "        self.n_bins = n_bins\n",
    "        self.binning_strategy = binning_strategy\n",
    "        self.column_pairs = column_pairs\n",
    "        self.src_cols = None\n",
    "        self.dest_cols = None\n",
    "        self.kbins_discretizor = KBinsDiscretizer(encode='ordinal', n_bins=self.n_bins, strategy=self.binning_strategy)\n",
    "        self.impute_value_dict = dict()\n",
    "        \n",
    "    def fit(self, x):\n",
    "        x = x.copy()\n",
    "        self.src_cols = [i for i, j in self.column_pairs] # key columns based on which dest cols are imputed\n",
    "        self.dest_cols = [j for i, j in self.column_pairs] # cols to be imputed based on src cols\n",
    "        self.kbins_discretizor.fit(x[self.src_cols].fillna(0)) # fitting src cols into keys, so that they can be grouped\n",
    "        binned_x = self.kbins_discretizor.transform(x[self.src_cols].fillna(0)).copy() # transforming src cols into bins\n",
    "        binned_x = pd.DataFrame(binned_x, columns=self.src_cols, index=x.index) # converting bin result to df from array\n",
    "        for src_col, dest_col in zip(self.src_cols, self.dest_cols):\n",
    "            # creating df with one col as binned src col and other as dest col.\n",
    "            # selecting first column using .iloc[:, 0] in case multiple cols are returned when self.src_cols=['a', 'a']\n",
    "            # or self.dest_cols=['a', 'a']. This happens when column_pairs are [['a', 'b'], ['a', 'c']]\n",
    "            df = pd.DataFrame({src_col: binned_x[[src_col]].iloc[:, 0], dest_col: x[[dest_col]].iloc[:, 0]}).dropna() \n",
    "            # grouping using binned src col and calculating median of dest col which can be used for imputation\n",
    "            df = df.groupby(src_col, as_index=False).median()\n",
    "            # Transforming result df into list of lists where first val is src bin val and second val is dest median val to impute\n",
    "            self.impute_value_dict[src_col+\"_\"+dest_col] = df.to_dict(orient=\"split\")['data']\n",
    "        return self\n",
    "            \n",
    "    def transform(self, x):\n",
    "        x = x.copy()\n",
    "        binned_x = self.kbins_discretizor.transform(x[self.src_cols].fillna(0)).copy() # transforming src cols into bins using prefitted kbinsdiscretizor\n",
    "        binned_x = pd.DataFrame(binned_x, columns=self.src_cols, index=x.index) # converting bin result to df from array\n",
    "        for src_col, dest_col in zip(self.src_cols, self.dest_cols):\n",
    "            for cat in self.impute_value_dict[src_col+\"_\"+dest_col]: # choosing values to impute based on src col\n",
    "                src_val = cat[0] # src_val = bin value\n",
    "                dest_val = cat[1] # dest_val = median val to impute\n",
    "                # if binned_x src col val = src_val and dest_col in x == NaN then impute dest col with dest_val\n",
    "                x.loc[(binned_x[[src_col]].iloc[:, 0] == src_val) & (x[[dest_col]].iloc[:, 0].isna()), dest_col] = dest_val\n",
    "        return x\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'NumAndNumImputer(column_pairs={self.column_pairs}, n_bins={self.n_bins}, binning_strategy={self.binning_strategy})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5198b940-70d9-4090-8563-22a04770f21e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CatAndNumImputer:\n",
    "    \n",
    "    '''\n",
    "    - Imputes a numeric feature using the values in another specified categorical feature.\n",
    "      Column pairs must be passed as input in the list of lists format like \n",
    "      [src_col, dest_col], where src_col and dest_col are categorical and numeric features respectively.\n",
    "    \n",
    "    - src_col is the column to be used as key for imputation and dest_col is column to be imputed.\n",
    "    \n",
    "    - During model fit, src_col is grouped and the median value of dest_col is computed and stored.\n",
    "    \n",
    "    - During transform, when a missing value is found in dest_col, it is imputed using the median value of\n",
    "      the corresponding category in src_col computed while fitting the model.\n",
    "      \n",
    "      Inputs:\n",
    "      column_pairs: list[list[str]]\n",
    "          Column pairs to be used for imputation          \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, column_pairs):\n",
    "        self.column_pairs = column_pairs\n",
    "        self.src_cols = None\n",
    "        self.dest_cols = None\n",
    "        self.impute_value_dict = dict()\n",
    "        \n",
    "    def fit(self, x):\n",
    "        x = x.copy()\n",
    "        self.src_cols = [i for i, j in self.column_pairs] # key columns based on which dest cols are imputed\n",
    "        self.dest_cols = [j for i, j in self.column_pairs] # cols to be imputed based on src cols\n",
    "        for src_col, dest_col in zip(self.src_cols, self.dest_cols):\n",
    "            # creating df with one col as src col and other as dest col.\n",
    "            # selecting first column using .iloc[:, 0] in case multiple cols are returned when self.src_cols=['a', 'a']\n",
    "            # or self.dest_cols=['a', 'a']. This happens when column_pairs are [['a', 'b'], ['a', 'c']]\n",
    "            df = pd.DataFrame({src_col: x[[src_col]].iloc[:, 0], dest_col: x[[dest_col]].iloc[:, 0]}).dropna() \n",
    "            # grouping using src col and calculating median of dest col which can be used for imputation\n",
    "            df = df.groupby(src_col, as_index=False).median()\n",
    "            # Transforming result df into list of lists where first val is src bin val and second val is dest median val to impute\n",
    "            self.impute_value_dict[src_col+\"_\"+dest_col] = df.to_dict(orient=\"split\")['data']\n",
    "        return self\n",
    "            \n",
    "    def transform(self, x):\n",
    "        x = x.copy()\n",
    "        for src_col, dest_col in zip(self.src_cols, self.dest_cols):\n",
    "            for cat in self.impute_value_dict[src_col+\"_\"+dest_col]: # choosing values to impute based on src col\n",
    "                src_val = cat[0] # src_val = groupby value\n",
    "                dest_val = cat[1] # dest_val = median val to impute\n",
    "                # if x src col val = src_val and dest_col in x == NaN then impute dest col with dest_val\n",
    "                x.loc[(x[[src_col]].iloc[:, 0] == src_val) & (x[[dest_col]].iloc[:, 0].isna()), dest_col] = dest_val\n",
    "        return x\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'CatAndNumImputer(column_pairs={self.column_pairs})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1bf037d-6840-484a-b897-0bc9eed43f52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CatAndCatImputer:\n",
    "    \n",
    "    '''\n",
    "    - Imputes a categorical feature using the values in another specified categorical feature.\n",
    "      Column pairs must be passed as input in the list of lists format like \n",
    "      [src_col, dest_col], where src_col and dest_col are categorical features.\n",
    "    \n",
    "    - src_col is the column to be used as key for imputation and dest_col is column to be imputed.\n",
    "    \n",
    "    - During model fit, src_col is grouped and the mode value of dest_col is computed and stored.\n",
    "    \n",
    "    - During transform, when a missing value is found in dest_col, it is imputed using the mode value of\n",
    "      the corresponding category in src_col computed while fitting the model.\n",
    "      \n",
    "      Inputs:\n",
    "      column_pairs: list[list[str]]\n",
    "          Column pairs to be used for imputation          \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, column_pairs):\n",
    "        self.column_pairs = column_pairs\n",
    "        self.src_cols = None\n",
    "        self.dest_cols = None\n",
    "        self.impute_value_dict = dict()\n",
    "        \n",
    "    def fit(self, x):\n",
    "        x = x.copy()\n",
    "        self.src_cols = [i for i, j in self.column_pairs] # key columns based on which dest cols are imputed\n",
    "        self.dest_cols = [j for i, j in self.column_pairs] # cols to be imputed based on src cols\n",
    "        for src_col, dest_col in zip(self.src_cols, self.dest_cols):\n",
    "            # creating df with one col as src col and other as dest col.\n",
    "            # selecting first column using .iloc[:, 0] in case multiple cols are returned when self.src_cols=['a', 'a']\n",
    "            # or self.dest_cols=['a', 'a']. This happens when column_pairs are [['a', 'b'], ['a', 'c']]\n",
    "            df = pd.DataFrame({src_col: x[[src_col]].iloc[:, 0], dest_col: x[[dest_col]].iloc[:, 0]}).dropna()\n",
    "            # grouping using src col and calculating most common value of dest col which can be used for imputation\n",
    "            df = df.groupby(src_col, as_index=False).agg(lambda k: Counter(k).most_common()[0][0])\n",
    "            # Transforming result df into list of lists where first val is src bin val and second val is dest median val to impute\n",
    "            self.impute_value_dict[src_col+\"_\"+dest_col] = df.to_dict(orient=\"split\")['data']\n",
    "        return self\n",
    "            \n",
    "    def transform(self, x):\n",
    "        x = x.copy()\n",
    "        for src_col, dest_col in zip(self.src_cols, self.dest_cols):\n",
    "            for cat in self.impute_value_dict[src_col+\"_\"+dest_col]: # choosing values to impute based on src col\n",
    "                src_val = cat[0] # src_val = groupby value\n",
    "                dest_val = cat[1] # dest_val = median val to impute\n",
    "                # if x src col val = src_val and dest_col in x == NaN then impute dest col with dest_val\n",
    "                x.loc[(x[[src_col]].iloc[:, 0] == src_val) & (x[[dest_col]].iloc[:, 0].isna()), dest_col] = dest_val\n",
    "        return x\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'CatAndCatImputer(column_pairs={self.column_pairs})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "612f9acc-d4e8-4e7a-a44e-c3f03ccd1ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumAndCatImputer:\n",
    "    \n",
    "    '''\n",
    "    - Imputes a categorical feature using the values in another specified numeric feature.\n",
    "      Column pairs must be passed as input in the list of lists format like \n",
    "      [src_col, dest_col], where src_col and dest_col are numeric and categorical features respectively.\n",
    "    \n",
    "    - src_col is the column to be used as key for imputation and dest_col is column to be imputed.\n",
    "    \n",
    "    - During model fit, src_col is binned and the mode value of dest_col is computed and stored.\n",
    "    \n",
    "    - During transform, when a missing value is found in dest_col, it is imputed using the mode value of\n",
    "      the corresponding bin in src_col computed while fitting the model.\n",
    "      \n",
    "      Inputs:\n",
    "      column_pairs: list[list[str]]\n",
    "          Column pairs to be used for imputation\n",
    "          \n",
    "      n_bins: int\n",
    "          Number of bins into whuch the src_col must be grouped using KBinsDiscretizer.\n",
    "          \n",
    "      binning_strategy: str: [\"uniform\", \"quantile\"]\n",
    "          Binning strategy to be used for binning the src_col using KBinsDiscretizer.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, column_pairs, n_bins=5, binning_strategy='quantile'):\n",
    "        self.n_bins = n_bins\n",
    "        self.binning_strategy = binning_strategy\n",
    "        self.column_pairs = column_pairs\n",
    "        self.src_cols = None\n",
    "        self.dest_cols = None\n",
    "        self.kbins_discretizor = KBinsDiscretizer(encode='ordinal', n_bins=self.n_bins, strategy=self.binning_strategy)\n",
    "        self.impute_value_dict = dict()\n",
    "        \n",
    "    def fit(self, x):\n",
    "        x = x.copy()\n",
    "        self.src_cols = [i for i, j in self.column_pairs] # key columns based on which dest cols are imputed\n",
    "        self.dest_cols = [j for i, j in self.column_pairs] # cols to be imputed based on src cols\n",
    "        self.kbins_discretizor.fit(x[self.src_cols].fillna(0)) # fitting src cols into keys, so that they can be grouped\n",
    "        binned_x = self.kbins_discretizor.transform(x[self.src_cols].fillna(0)).copy() # transforming src cols into bins\n",
    "        binned_x = pd.DataFrame(binned_x, columns=self.src_cols, index=x.index) # converting bin result to df from array\n",
    "        for src_col, dest_col in zip(self.src_cols, self.dest_cols):\n",
    "            # creating df with one col as binned src col and other as dest col.\n",
    "            # selecting first column using .iloc[:, 0] in case multiple cols are returned when self.src_cols=['a', 'a']\n",
    "            # or self.dest_cols=['a', 'a']. This happens when column_pairs are [['a', 'b'], ['a', 'c']]\n",
    "            df = pd.DataFrame({src_col: binned_x[[src_col]].iloc[:, 0], dest_col: x[[dest_col]].iloc[:, 0]}).dropna() \n",
    "            # grouping using binned src col and calculating most common value of dest col which can be used for imputation\n",
    "            df = df.groupby(src_col, as_index=False).agg(lambda k: Counter(k).most_common()[0][0])\n",
    "            # Transforming result df into list of lists where first val is src bin val and second val is dest median val to impute\n",
    "            self.impute_value_dict[src_col+\"_\"+dest_col] = df.to_dict(orient=\"split\")['data']\n",
    "        return self\n",
    "            \n",
    "    def transform(self, x):\n",
    "        x = x.copy()\n",
    "        binned_x = self.kbins_discretizor.transform(x[self.src_cols].fillna(0)).copy() # transforming src cols into bins using prefitted kbinsdiscretizor\n",
    "        binned_x = pd.DataFrame(binned_x, columns=self.src_cols, index=x.index) # converting bin result to df from array\n",
    "        for src_col, dest_col in zip(self.src_cols, self.dest_cols):\n",
    "            for cat in self.impute_value_dict[src_col+\"_\"+dest_col]: # choosing values to impute based on src col\n",
    "                src_val = cat[0] # src_val = bin value\n",
    "                dest_val = cat[1] # dest_val = median val to impute\n",
    "                # if binned_x src col val = src_val and dest_col in x == NaN then impute dest col with dest_val\n",
    "                x.loc[(binned_x[[src_col]].iloc[:, 0] == src_val) & (x[[dest_col]].iloc[:, 0].isna()), dest_col] = dest_val\n",
    "        return x\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'NumAndCatImputer(column_pairs={self.column_pairs}, n_bins={self.n_bins}, binning_strategy={self.binning_strategy})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a349dc5f-68d5-433e-8803-6afb5c4845d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MissingImputer:\n",
    "    \n",
    "    '''\n",
    "    - Imputes numeric and categorical features based on the strategies specified.\n",
    "    \n",
    "    - Strategies must be specified as a dict like {column_name: strategy}.\n",
    "    \n",
    "    - Strategies supported are \"mean\", \"median\", \"mode\".\n",
    "    \n",
    "    - User can also pass in a numeric value and a str value which are used for imputing as a constant\n",
    "    \n",
    "    - Example: strategies={\"col_1\": \"mean\", \"col_2\": \"median\", \"col_3\": \"mode\", \n",
    "                           \"col_4\": \"not_available\", \"col_5\": 9999}\n",
    "      \n",
    "    - \"not_available\" and 9999 are examples of constant values to be imputed in categorical and numeric \n",
    "      columms respectively.\n",
    "      \n",
    "      Inputs:\n",
    "      strategies: dict\n",
    "          Dict specifying imputation strategies.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, strategies: dict):\n",
    "        self.strategies = strategies\n",
    "        self.impute_values = {}\n",
    "        \n",
    "    def fit(self, x):\n",
    "        x = x.copy()\n",
    "        for col in self.strategies:\n",
    "            col_data = x[col].dropna()\n",
    "            if self.strategies[col] == 'mean':\n",
    "                self.impute_values[col] = np.mean(col_data)\n",
    "            elif self.strategies[col] == 'median':\n",
    "                self.impute_values[col] = np.median(col_data)\n",
    "            elif self.strategies[col] == 'mode':\n",
    "                mode_ = Counter(col_data).most_common(1)[0][0]\n",
    "                self.impute_values[col] = mode_\n",
    "            else:\n",
    "                self.impute_values[col] = self.strategies[col]\n",
    "        return self\n",
    "                \n",
    "    def transform(self, x):\n",
    "        x = x.copy()\n",
    "        for col in self.impute_values:\n",
    "            x[col] = x[col].fillna(self.impute_values[col])\n",
    "        return x\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'MissingImputer(strategies={self.strategies})'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cb8f1c-8de1-4b1b-82bb-b3bb038d598b",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cce091-f9fd-41c8-9063-c4e6afa1acba",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### data source: https://www.kaggle.com/datasets/arashnic/hr-analytics-job-change-of-data-scientists/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6896d7c-ea4a-407c-9373-d8fc1a689d62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('aug_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ac8228f-7688-400b-b111-f7377c333634",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enrollee_id                 int64\n",
       "city                       object\n",
       "city_development_index    float64\n",
       "gender                     object\n",
       "relevent_experience        object\n",
       "enrolled_university        object\n",
       "education_level            object\n",
       "major_discipline           object\n",
       "experience                 object\n",
       "company_size               object\n",
       "company_type               object\n",
       "last_new_job               object\n",
       "training_hours              int64\n",
       "target                    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a61b635-5eb9-44ac-bdc1-a0e661e3cde6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enrollee_id                  0\n",
       "city                         0\n",
       "city_development_index       0\n",
       "gender                    4508\n",
       "relevent_experience          0\n",
       "enrolled_university        386\n",
       "education_level            460\n",
       "major_discipline          2813\n",
       "experience                  65\n",
       "company_size              5938\n",
       "company_type              6140\n",
       "last_new_job               423\n",
       "training_hours               0\n",
       "target                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24753699-2919-4463-8268-29ba93720873",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Using CatAndCatImputer to impute categorical features using another categorical feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3b3d07-da1c-45e3-b0bc-11639ea1fe5b",
   "metadata": {},
   "source": [
    "Using city feature to impute missing values in gender feature (['city', 'gender']), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53c979e7-1987-4bc0-b91e-f8394fb1ce2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_cat_imputer = CatAndCatImputer(column_pairs=[['city', 'gender'], ['city', 'education_level'], ['education_level', 'major_discipline'], \n",
    "                                                 ['education_level', 'experience'], ['experience', 'last_new_job'], ['education_level', 'enrolled_university']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb40db72-391a-43a5-9716-a737a23a39bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CatAndCatImputer(column_pairs=[['city', 'gender'], ['city', 'education_level'], ['education_level', 'major_discipline'], ['education_level', 'experience'], ['experience', 'last_new_job'], ['education_level', 'enrolled_university']])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cat_imputer.fit(data) # fititng imputer to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7bfeee6-4c45-414e-9fd4-f7d367f22de7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cat_cat_imputer.impute_value_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bbcd1c9-3bd9-484a-ab97-383adb96cc6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = cat_cat_imputer.transform(data) # transforming data and storing it in res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1b4d52-f1a1-4350-9d0c-f60befee97a1",
   "metadata": {},
   "source": [
    "##### Using NumAndCatImputer to impute categorical features using another categorical feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2a2022-a2ce-41c7-9ae2-f5414439f284",
   "metadata": {
    "tags": []
   },
   "source": [
    "Using city_development_index feature to impute missing values in company_size feature (['city_development_index', 'company_size']), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e429b53e-312f-40a4-8d48-13967eb61deb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_cat_imputer = NumAndCatImputer(column_pairs=[['city_development_index', 'company_size'], ['city_development_index', 'company_type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcb16cc6-9595-47aa-96c7-618c97016814",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NumAndCatImputer(column_pairs=[['city_development_index', 'company_size'], ['city_development_index', 'company_type']], n_bins=5, binning_strategy=quantile)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cat_imputer.fit(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f689bb76-dd6a-49ed-a1e6-3a36b4b41b0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'city_development_index_company_size': [[0.0, '50-99'],\n",
       "  [1.0, '50-99'],\n",
       "  [2.0, '50-99'],\n",
       "  [3.0, '50-99']],\n",
       " 'city_development_index_company_type': [[0.0, 'Pvt Ltd'],\n",
       "  [1.0, 'Pvt Ltd'],\n",
       "  [2.0, 'Pvt Ltd'],\n",
       "  [3.0, 'Pvt Ltd']]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cat_imputer.impute_value_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d0a1819-d7da-4cdd-941c-2938c8f28b0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = num_cat_imputer.transform(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ece644f-4657-449a-8afe-412b2f1e3691",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### There are missing values left in gender and major_discipline features which couldn't be filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc2606e7-7f32-4a95-8fd1-8b09d16ccb3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enrollee_id                  0\n",
       "city                         0\n",
       "city_development_index       0\n",
       "gender                       1\n",
       "relevent_experience          0\n",
       "enrolled_university          0\n",
       "education_level              0\n",
       "major_discipline          2327\n",
       "experience                   0\n",
       "company_size                 0\n",
       "company_type                 0\n",
       "last_new_job                 0\n",
       "training_hours               0\n",
       "target                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7591e0-4819-44d0-ae0b-e6b5645a8640",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Below we can see that gender is still 1 missing value for city_171"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9f78f7b-87fb-4279-9c0a-12fb25df1a07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14451</th>\n",
       "      <td>city_171</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           city gender\n",
       "14451  city_171    NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.loc[res['gender'].isna(), ['city', 'gender']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458e6176-80a5-4503-b1d7-f821e6220c6a",
   "metadata": {},
   "source": [
    "##### We can see that there is only 1 sample having city_171 and that too has missing gender value, due to which the gender value couldn't be imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7188978-2f4f-459d-9eed-81e8187ae924",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14451</th>\n",
       "      <td>city_171</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           city gender\n",
       "14451  city_171    NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.loc[res['city'] == 'city_171', ['city', 'gender']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55269d3-2e88-4d78-b4c1-d2347ef422ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Below we can see that where the major_discipline is still missing, the education_level is ['High School', 'Primary School'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e66bdd45-c1d6-4edd-abc5-85d268e75f11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education_level</th>\n",
       "      <th>major_discipline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>High School</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Primary School</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    education_level major_discipline\n",
       "6       High School              NaN\n",
       "213  Primary School              NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.loc[res['major_discipline'].isna(), ['education_level', 'major_discipline']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c6e051-521a-48ce-a5da-f19c992b347e",
   "metadata": {},
   "source": [
    "##### But we couldn't find ['High School', 'Primary School'] in imputation list below. As seen above, all the major_discipline values are missing for education_level ['High School', 'Primary School']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6553727-eff1-45e7-a897-3f11942bd833",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Graduate', 'STEM'], ['Masters', 'STEM'], ['Phd', 'STEM']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cat_imputer.impute_value_dict['education_level_major_discipline']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aaf838-07fc-4edd-a858-eb4f0e768380",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### This seems logical as a person with ['High School', 'Primary School'] education cannot have a major_discipline. So these values must be marked separately, instead of marking them with mode. So we'll be imputing it with a constant value \"not_applicable\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d416bc84-7bb9-485d-8d5c-3d0b0bc1a0dc",
   "metadata": {},
   "source": [
    "##### Finally, we'll use MissingImputer to impute any left over missing values with mean/mode/constant. We'll add strategy for every column to impute any left over missing values, just in case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e38664a-202d-4116-826c-8b77c457b98e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "strategies = {\"enrollee_id\": -1, \"city\": \"missing\", \"city_development_index\": \"mean\", \"gender\": \"mode\", \n",
    "\"relevent_experience\": \"mode\", \"enrolled_university\": \"mode\", \"education_level\": \"mode\", \n",
    "\"major_discipline\": \"not_applicable\", \"experience\": \"mode\", \"company_size\": \"mode\", \n",
    "\"company_type\": \"mode\", \"last_new_job\": \"not_available\", \"training_hours\": \"mean\", \"target\": \"mode\"}\n",
    "\n",
    "missing_imputer = MissingImputer(strategies=strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "785d97ff-a55f-401a-be11-c2d49a9efb9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MissingImputer(strategies={'enrollee_id': -1, 'city': 'missing', 'city_development_index': 'mean', 'gender': 'mode', 'relevent_experience': 'mode', 'enrolled_university': 'mode', 'education_level': 'mode', 'major_discipline': 'not_applicable', 'experience': 'mode', 'company_size': 'mode', 'company_type': 'mode', 'last_new_job': 'not_available', 'training_hours': 'mean', 'target': 'mode'})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_imputer.fit(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bf3e724-8db5-4886-aba0-5cccd1051a67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enrollee_id': -1,\n",
       " 'city': 'missing',\n",
       " 'city_development_index': 0.8288480008351603,\n",
       " 'gender': 'Male',\n",
       " 'relevent_experience': 'Has relevent experience',\n",
       " 'enrolled_university': 'no_enrollment',\n",
       " 'education_level': 'Graduate',\n",
       " 'major_discipline': 'not_applicable',\n",
       " 'experience': '>20',\n",
       " 'company_size': '50-99',\n",
       " 'company_type': 'Pvt Ltd',\n",
       " 'last_new_job': 'not_available',\n",
       " 'training_hours': 65.36689633573442,\n",
       " 'target': 0.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_imputer.impute_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1ffc069-dfcc-4f14-9731-ee03b5c4d496",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = missing_imputer.transform(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f076646b-06e7-412c-8a4e-6bda6e5553d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enrollee_id               0\n",
       "city                      0\n",
       "city_development_index    0\n",
       "gender                    0\n",
       "relevent_experience       0\n",
       "enrolled_university       0\n",
       "education_level           0\n",
       "major_discipline          0\n",
       "experience                0\n",
       "company_size              0\n",
       "company_type              0\n",
       "last_new_job              0\n",
       "training_hours            0\n",
       "target                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.isna().sum() # no missing values left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a591c2-911a-4f1d-a251-358e0e2f21b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
